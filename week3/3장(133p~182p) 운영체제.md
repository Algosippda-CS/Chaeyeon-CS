# 3장(133p~182p)

# 3.1 운영체제와 컴퓨터

## 운영체제의 역할과 구조

### 운영체제의 역할

1. **CPU 스케줄링과 프로세스 관리 :** CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리합니다.
2. **메모리 관리 :** 한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 하는지 관리합니다.
3. **디스크 파일 관리 :** 디스크 파일을 어떠한 방법으로 보관할지 관리합니다.
4. **I/O 디바이스 관리 :**  I/O 디바이스들인 마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리합니다.

### 운영체제의 구조

![Untitled](3장(133p~182p) 운영체제/Untitled 1.png)

**시스템콜**

- 운영체제가 커널에 접근하기 위한 인터페이스
- 유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수 호출 시 사용
- fs.readFile() 같은 함수 발동 시 , 유저 모드에서 파일을 읽지 않고 커널 모드로 들어가 파일을 읽은 후 유저모드로 돌아가 그 뒤에 있는 유저 프로그램의 로직을 수행함.
    
    ![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%201.png)
    
     ⇒ 컴퓨터 자원 직 접 접근 차단 및 프로그램을 타 프로그램으로 부터 보호 기능
    

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%202.png)

프로세스나 스레드에서 운영체제로 요청 시 시스템 콜이라는 인터페이스와 커널을 거쳐 운영체제에 전달 된다. 

- 장점 : 시스템 콜은 추상화 계층의 하나이기 때문에, 낮은 단계 영역 처리(네트워크 통신, 데이터 베이스)에 대한 부분을 많이 신경 쓰지 않고 프로그램 구현이 가능하다

**modebit**

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%203.png)

- 시스템 콜 작동 시 modebit을 참고해서 유저모드와 커널 모드를 구분함.
- 0(커널 모드)과 1(유저 모드)의 값을 가지는 플래그 변수
- 디바이스는 운영체제를 통해서만 작동해야하기 때문에 커널 모드로 작동하게 해야함 이를 위한 장치가 modebit

## 컴퓨터의 요소

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%204.png)

컴퓨터 구성요소 : **CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러**

### cpu

- Central Processing Unit
- 산술 논리연산 장치, 제어장치, 레지스터로 구성
- 인터럽트에 의해 단순 메모리에 존재하는 명령어 해석 및 실행
- 관리자인 운영체제 커널이 프로그램을 메모리에 올려 프로세스로 만들면, CPU가 이를 처리
    
    **제어장치(CU)**
    
    - 프로세스 조작을 지시하는 cpu 부품
    - 입출력 장치 간 통신 제어
    - 명령어 읽고 해석
    - 데이터 처리 순서 결정
    
    **레지스터**
    
    - 매우 빠른 임시기억장치 in cpu
    - 연산 속도가 메모리보다 훨씬 빠름
    - cpu가 자체적으로 데이터 저장을 못하기때문에 레지스터를 거쳐 데이터 전달 받음
    
    **산술 논리 연산 장치( ALU)**
    
    - 두 숫자의 산술 연산, 논리 연산을 계산하는 디지털 회로 in cpu
    
    **인터럽트**
    
    - 어떤 신호가 들어왔을 때 CPU를 잠시 정지시키는 것
    - IO 디바이스로 인한 인터럽트 , 산술 연산의 인터럽트, 프로세스 오류 등으로 발생
    - 인터럽트 간 우선순위 존재
    - 발생 시 인터럽트 벡터로 가서 인터럽트 핸들러 함수가 실행됨
        
        **하드웨어 인터럽트**
        
        - 키보드 연결 등의 IO 디바이스에서 발생
        - 순차적 인터럽트 실행 중지 후 , 운영체제에 시스템 콜을 요청하여 원하는 디바이스에 있는 작은 로컬 버퍼에 접근하여 일 수행
        
        **소프트웨어 인터럽트**
        
        - aka 트랩(trap)
        - 프로세스 오류 등으로 프로세스가 시스템 콜 호출 시 발생

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%205.png)

### DMA 컨트롤러

- IO 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
- 너무 많은 인터럽트 요청이 들어오는 cpu의 부하를 막아주며 cpu일을 부담해주는 보조 일꾼
- 하나의 작업을 cpu와 dma 컨트롤러가 동시에 하는 것을 방지

### 메모리

- 전자회로에서 데이터, 상태, 명령어 등을 기록하는 장치
- aka RAM
- cpu는 계산 담당(일꾼), 메모리는 기억 담당( 작업장)

### 타이머

- 몇초 안에 작업이 끝나야 한다는 것을 정하고 특정 프로그램에 시간 제한을 다는 역할

### 디바이스 컨트롤러

- 컴퓨터와 연결되어있는 IO 디바이스들의 작은 CPU

# 3.2 메모리

## 메모리 계층

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%206.png)

구성 : 레지스터, 캐시, 메모리, 저장장치 

- 레지스터 : CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적습니다.
- 캐시 : L1, L2 캐시를 지칭합니다. 휘발성, 속도 빠름, 기억 용량이 적습니다. 참고로 L3 캐시도 있습니다.
- 주기억 장치 : RAM을 가리킵니다. 휘발성, 속도 보통, 기억 용량이 보통입니다
- 보조기억 장치 : : HDD, SSD* 일컬으며 비휘발성, 속도 낮음, 기억 용량이 많습니다
    
    ⇒ 램은 하드디스크로부터 일정량 데이터 복사해서 임시 저장하고 , 필요 시마다 cpu 에 빠르게 전달하는 역할을 함.
    
    ⇒ 위의 계층으로 갈 수록 가격은 비싸짐, 속도는 빨라짐, 용량은 작아짐.
    

**캐시**

- 데이터를 미리 복사해 놓는 임시 저장소
- 빠른 장치와 느린 장치사이의 속도차이에 따른 병목 현상을 줄임
- 레지스터도 메모리와 cpu 사이에서 캐싱 역할을 함
- 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층 → “캐싱 계층”
- 따라서 주기억장치를 (캐시와) 보조기억장치의 캐싱 계층이라 볼 수 있음

**지역성**

- 자주 사용하는 데이터를 기반으로 캐시를 설정해야함
- 자주 사용하는 근거는 “ 지역성 “ 에 따름
- 시간 지역성과 공간 지역성 존재
    
    **시간 지역성**
    
    - 최근 사용한 데이터에 다시 접근하려는 특성
    
    **공간 지역성**
    
    - 최근 접근한 데이터를 이루고 있는 공간이나, 그 인접공간에 접근하는 특성

### 캐시히트와 캐시미스

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%207.png)

**캐시 히트** : 캐시에서 원하는 데이터를 찾는데 성공

**캐시 미스** : 해당 데이터가 캐시에 없어서, 주 메모리로 가서 데이터를 찾아옴. 

- 캐시 히트 시 해당 데이터를 **cpu 내부 버스 기반**으로 제어장치를 거쳐 가져옴 → 매우 빠름
- 캐시 미스 시 **시스템 버스를 기반**으로 메모리에서 가져옴→ 느림

**캐시매핑 : 캐시가 히트되기 위해 매핑하는 방법 , cpu 레지스터와 주메모리(RAM) 사이 데이터 주고 받을 때를 기반으로 함.**

- 캐시 계층으로써 레지스터가 역할을 잘하기 위해 “ 캐시 매핑” 을 어떻게 하는가가 중요함.
    
    **직접 매핑 : 메모리가 1~100 있고, 캐시가 1~10 있으면, 1: 1~10, 2:1~20 이런식으로 매핑 함** 
    
    ⇒ 처리가 빠르지만 충돌 발생 많음
    
    **연관 매핑 : 순서를 일치 시키지 않고 관련 있는 캐시와 메모리를 매핑**
    
    ⇒ 충돌이 적지만 모든 블록 탐색해야해서 느림
    
    **집합 연관 매핑 : 직접 매핑과 연관 매핑을 합쳐 놓은 것, 순서는 일치 시키 지만 집합을 두어 저장하며 블록화 되어있어 검색을 더 효율적.** 
    
    ⇒ 예시) 메모리 1~100, 캐시 1~10일 경우, 캐시 1~5에 1~50의 데이터를 무작위로 저장시킴.
    

**웹 브라우저의 캐시**

쿠키 : 만료기한 존재/ 키- 값 저장소/4KB

로컬 스토리지 : 만료기한 없음/키-값 저장소/ 10MB/도메인 단위로 저장, 생성/브라우저 닫아도 유지/ 클라이언트에서만 수정가능

세션 스토리지 : 만료기한 없음/ 키-값 저장소 / 5MB/ 탭 닫을 시 데이터도 삭제됨/ 클라이언트에서만 수정가능

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%208.png)

⇒ 레디스를 캐싱 계층으로 사용해서 성능 향상.

## 메모리관리

### 가상 메모리

- 메모리 관리 기법 중 하나
- 실제로 이용가능한 메모리 자원을 추상화 하여, 매우 큰 메모리로 보이게 만드는 것
- 가상 주소(logical address)와  실제주소(physical address) 존재
- 가상주소는 메모리 관리장치에 의해 실제주소로 변환됨
- 가상 메모리는 가상 주소와 실제 주소가 매핑되어있고, 프로세스 주소 정보가 들어있는 ‘페이지 테이블’로 관리됨 ⇒ 속도 향상을 위해 TLB 사용(메모리-cpu 간의 주소변환을 위한 캐시)

**스와핑**

- 가상 메모리는 존재하지만 실제 메모리 RAM에 현재 없는 데이터나 코드에 접근시 페이지 폴트 발생
- 당장 사용하지않는 메모리영역을 하드디스크로 옮기고, 하드디스크 일부분을 메모리처럼 불러와 쓰는 것이 ‘스와핑’
    
    ⇒ **페이지 폴트가 일어나지 않은 것처럼** 만듦
    

**페이지 폴트(page fault)**

- 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우 발생
    
    1.  CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제에 알림.
    2. 운영체제는 CPU의 동작을 잠시 멈춤
    3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어 있는 프레임이 있는지 찾음.                                물리 메모리에도 없다면 스와핑 발동
    4. 비어 있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화합니다.
    5. 중단되었던 CPU를 다시 시작합니다.
    

### 스레싱(thrashing)

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%209.png)

- 메모리의 페이지 폴트율이 높은 것 의미
- 컴퓨터의 심각한 성능 저하 초래
- 메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 일어나서 발생
- 페이지 폴트 발생 →cpu 이용률 낮아짐 → 운영체제가 cpu 한가하다고 착각 → 더 많은 프로세스를 메모리에 올림 →악순환 반복
- 해결 방법 : 메모리 늘림, SSD 사용, 작업 세트, PFF
    
    **작업 세트**
    
    - 프로세스의 지역성을 통해 결정된 페이지 집합을 만들어 미리 메모리에 로드하는 것
    - 탐색에 드는 비용 절감, 스와핑 절감
    
    **PFF**
    
    - 페이지 폴트 빈도를 조절하는 방법
    - 상한선과 하한선을 만드는 방법
    - 상한선에 도달하면, 프레임 증가시킴, 하한선에 도달하면 프레임 감소시킴
    

### 메모리 할당

- 시작 메모리 위치, 메모리 할당 크기를 기반으로 할당합니다.

**연속 할당**

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%2010.png)

- 메모리에 ‘연속적으로’ 공간을 할당하는 방법
- 메모리 관리 방식 두가지
    
    **고정 분할 방식**
    
    - 메모리를 미리 나누어 관리하는 방식
    - 미리 나눠놔서 융통성 X, 내부 단편화 초래
    
    **가변 분할 방식**
    
    - 매 시점마다 동적으로 크기에 맞게 메모리를 나눠 사용
    - 내부단편화 X, 외부 단편화 발생 가능
    - 최초적합 : 위쪽이나 아래부터 시작해서 홀 찾으면 바로 할당
    - 최적적합 : 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당
    - 최악적합 : 프로세스 크기와 가장 차이 많이 나는 홀에 할당.

<aside>
❓ **— 내부단편화**                                                                                                                                            메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상

</aside>

<aside>
❓ **— 외부 단편화**                                                                                                                                메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상,

</aside>

**불연속 할당**

- 메모리를 연속적으로 할당하지 않는 방식으로 현대 운영체제가 쓰는 방식인 ‘페이징 기법’이 있음
    - **페이징 : 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스 할당**
        
        ⇒ 홀의 크기 균일 하지 않은 문제 해결, but 주소 변환 복잡
        
    - **세그멘테이션 : 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식**
        
        ⇒ 공유, 보안 측면에서 good, but 홀 크기가 균일하지 않음
        
    - **페이지드 세그멘테이션 : 프로그램을 의미 단위인 세그먼트로 나눠 동일한 크기의 페이지 단위로 나누는 것**
    - ⇒ 공유, 보안 측면 good

### 페이지 교체 알고리즘

- 페이지 교체 알고리즘을 기반으로 스와핑이 일어남으로, 많이 일어나지 않도록 설계해야함.

**오프라인 알고리즘**

- 가장 좋은 알고리즘 → 상한 기준으로 사용하여 성능 비교에 사용
- 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘
- 근데 미래에 사용될 프로세스를 아는건 불가능→ 실제론 사용 불가

**FIFO**

- 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

**LRU**

- 참조가 가장 오래된 페이지를 바꿈,
- 단점: ‘오래됨’ 파악을 위해 각 페이지마다 계수기 및 스택을 두어야 함
- 해시 테이블 + 이중 연결 리스트 로 구현

**NUR**

- LRU에서 발전
- aka clock 알고리즘
- 0과1을 가진 비트로 1은 최근 참조, 0은 참조X를 의미
- 시계 방향을 돌며 0을 찾으면 해당 프로세스를 교체하고 , 1로 비트 교체함

**LFU**

- 가장 참조 횟수가 적은 (많이 사용 안한) 페이지 교체

# 3.3 프로세스와 스레드

프로세스: 컴퓨터에서 실행되고 있는 프로그램 == task

스레드 : 프로세스 내 작업 흐름

⇒ 프로그램이 메모리에 올라가면 프로세스가 되는 인스턴스화 발생, 이후 cpu 스케줄러에 따라 cpu가 프로세스 실행

## 프로세스와 컴파일 과정

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%2011.png)

### 전처리

소스 코드의 주석 제거, #include 헤더파일을 병합하여 매크로를 치환

### 컴파일러

오류 처리, 코드 최적화 작업을 하며 어셈블리어로 변환

### 어셈블러

어셈블리어를 목적 코드(object code)로 변환

리눅스의 경우 .o

### 링커

프로그램 내의 라이브러리 함수 또는 다른 파일,과 목적 코드를 결합하여 실행파일 생성

.exe 혹은 .out의 확장자를 갖음

## 프로세스의 상태

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%2012.png)

### 생성 상태(create)

프로세스가 생성된 상태 

fork(), exec() 함수를 통해 생성

PCB 할당

### 대기 상태(ready)

메모리 공간이 충분하면, 메모리를 할당받고 아니면 대기하면서 cpu스케줄러로부터 cpu 소유권이 넘어오길 기다리는 상태

### 대기 중단 상태(ready suspended)

메모리 부족으로 일시 중단된 상태

### 실행 상태(running)

cpu 소유권과 메모리를 할당받고 인스트럭션을 수행 중인 상태

> CPU burst 가 일어났다고 표현
> 

### 중단 상태(blocked)

어떤 이벤트 발생 후 기다리며, 프로세스가 차단된 상태

IO 디바이스 인터럽트로 인해 많이 발생

### 일시 중단 상태(blocked suspended)

대기 중단과 유사, 중단된 상태에서 프로세스가 실행되려 했지만 메모리 부족으로 일시 중단된 상태

### 종료 상태(terminated)

메모리와 cpu 소유권을 모두 놓고 가는 상태

## 프로세스의 메모리 구조

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC(133p~182p)%20bb88e8aafaff457884dc282f07695bd9/Untitled%2013.png)

- 스택은 위에서 아래로, 힙은 아래서 위로 할당됨.

### 스택과 힙

- 스택과 힙은 동적 할당 (런타임 단계 메모리 할당)
- 스택 : 지역변수, 매개변수 , 실행되는 함수에 의해 늘/줄어드는 메모리 영역
- 힙 : 동적 할당 변수 , malloc() , free()함수를 통해 관리 ex) vector

### 데이터 영역과 코드 영역

- 정적 할당 영역 ( 컴파일 단계 메모리 할당)
- BSS segment: 전역 변수 또는 static, const로 선언되어 있고 0으로 초기화 또는 초기화
가 어떠한 값으로도 되어 있지 않은 변수
- Data segment: 전역 변수 static, const 선언, 0이 아닌 값으로 초기화된 변수
- code segment : 프로그램 코드

## PCB

PCB(process control block) : 운영체제에서 프로세스에 대한 메타데이터를 저장한 ‘데이터’

- aka 프로세스 제어 블록
- 프로세스가 생성될 때 운영체제는 해당 PCB 생성되며, 해당 프로세스의 메타데이터가 PCB에 저장되어 관리
- 프로세스 중요 정보 포함되어 있으므로, 일반 사용자가 접근하지 못하도록, 커널 스택 가장 앞부분에서 관리

**PCB의 구조**

- 프로세스 스케줄링 상태 : ‘준비’, ‘일시중단’ 등 프로세스가 cpu에 대한 소유권을 얻은 이후의 상태
- 프로세스 ID : 프로세스 ID, 해당 프로세스의 자식 프로세스 ID
- 프로세스 권한 : 컴퓨터 자원 또는 IO 디바이스에 대한 권한 정보
- 프로그램 카운터 : 프로세스에서 실행해야 할 다음 명령어의 주소에 대한 포인터
- cpu 레지스터 : 프로세스를 실행하기 위해 저장해야 할 레지스터에 대한 정보
- cpu 스케줄링 정보 : cpu 스케줄러에 의해 중단된 시간 등에 대한 정보
- 계정 정보 : 프로세스 실행에 사용된 cpu 사용량, 실행한 유저의 정보
- I/O 상태 정보 : 프로세스에 할당된 io 디바이스 목록

**컨텍스트 스위칭**

- PCB를 교환하는 과정
- 한 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해 발생

#싱글 코어를 기준으로 설명

그림

1. 프로세스 A가 실행하다 멈춤
2. 프로세스 A의 PCB를 저장하고 다시 프로세스 B를 로드하여 실행
3. 다시 프로세스 B의 PCB를 저장하고,프로세스 A의 PCB를 로드한다

⇒ 컨텍스트 스위칭 발생 시 유휴시간(idle time) 이 발생 / 컨텍스트 스위칭에 드는 비용 = 캐시미스

**캐시미스**

- 컨텍스트 스위칭 일어날 때 프로세스가 가진 메모리 주소가 그대로 있으면, 잘못된 주소변환이 생기므로 캐시클리어 과정을 겪게 되고 → 캐시미스 발생

**스레드에서의 컨텍스트 스위칭**

- 스레드는 스택 영역을 제외한 모든 메모리를 공유하기 때문에 스레트 컨텍스트 스위칭은 **비용이 더 적고 시간도 적게 걸린다**.

## 멀티프로세싱

여러 개의 ‘프로세스’ , 즉 멀티 프로세스를 통해 동시에 두가지 이상의 일을 수행 하는 것

일을 병렬로 처리가능

특정 프로세스에 문제가 발생해도 다른 프로세스 이용하면 되므로 신뢰성 높음

**웹브라우저**

웹브라우저의 멀티 프로세스 구조

- 브라우저 프로세스 : 주소 표시줄, 북마크 막대,뒤로가기 버튼, 앞으로 가기 버튼 등을 담담/ 네트워크 요청이나 파일 접근과 같은 ‘권한’ 담당
- 랜더러 프로세스 : 웹사이트가 ‘보이는’ 부분의 모든 것을 제어
- 플러그인 프로세스 : 웹사이트에서 사용하는 플러그인을 제어
- gpu 프로세스 : gpu를 이용해서 화면을 그리는 부분을 제어

**IPC**

멀티 프로세스는 IPC(Inter Process Communication)이 가능

IPC는 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘

- 공유메모리
    - 여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 공유 메모리를 생성해서 통신하는 것
    - 기본적으로 각 프로세스의 메모리를 타 프로세스가 접근 불가
    - 공유 메모리를 통해 여러 프로세스가 하나의 메모리 공유 가능
    - 불필요한 데이터 복사의 오버헤드가 없어 가장 빠름 , 공유 해야하기 때문에 동기화 필요
    - 하드웨어 관점에서 RAM 의미
- 파일
    - 디스크에  저장된 데이터 또는 파일 서버에서 제공한 데이터
- 소켓
    - 동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터
    - TCP / UDP
- 익명 파이프
    - 프로세스 간 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고 받음
    - 읽기 전용, 쓰기 전용 파이프를 통해 작동
    - 조건 : 부모 자식 프로세스 간에만 사용 가능
- 명명된 파이프
    - 파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 양방향 파이프
    - 클라이언트/ 서버 용 파이프 구분 작동
    - 여러 파이프 동시 사용 가능
    - 한 컴퓨터 프로세스 끼리, 다른 네트워크 상 컴퓨터 와도 통신 가능
- 메시지 큐
    - 메시지를 큐 데이터 구조 형태로 관리 하는 것
    - 커널에서 전역적으로 관리
    - 장점 : 다른 IPC 방식에 비해 사용이 직관적, 간단함
    - 쓰기 및 읽기 빈도가 높으면 공유 메모리를 통한 IPC는 동기화 때문에 복잡해지는데, 대안으로 메시지 큐 사용

## 스레드와 멀티스레딩

**스레드** 

- 프로세스 실행 가능한 가장 작은 단위
- 프로세스는 여러 스레드 가질 수 O
- 프로세스는 <코드, 데이터, 스택, 힙> 각각 생성 하지만, 스레드는 <코드, 데이터, 힙> 은 서로 공유하면, 그 외 영역만 각각 생성

**멀티 스레딩**

- 프로세스 내 작업을 여러 개의 스레드로 처리하는 기법
- 스레드끼리 자원을 공유하기 때문에 효율성이 큼.
- ex) 웹요청 처리 -
    
    장점 : 프로세스 대신 스레드 사용하면 훨씬 적은 리소스 소비
    
    / 한 스레드가 중단 상태여도 다른 스레드는 실행 가능 ⇒ 빠른 처리 가능
    
    /  동시성 good
    
    단점 : 한 스레드에 문제가 생기면 다른 스레드에 영향 ⇒ 해당 프로세스에 영향 O
    
- 멀티 스레드 예시 - 랜더러 프로세스( 메인 스레드 / 워커 스레드/ 컴포지터 스레드/ 레스터 스레드)

## 공유 자원과 임계 영역

**공유 자원**

- 시스템 안에서 각 프로세스, 스레드가 함께 접근 할 수 있는 자원이나 변수
- 경쟁 상태 (race condition) : 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황

**임계 영역**

- 둘 이상의 프로세스, 스레드가 공유 자원에 접근 할 때 순서 등의 이유로 결과가 달라지는 코드 영역
- 해결 방법 : 뮤텍스, 세마포어, 모니터 ( **상호 배제, 한정 대기, 융통성** < 세가지 조건 만족)
    
    **뮤텍스**
    
    - 프로세스나 스레드가 공유 자원을 lock()을 통해 잠금 설정하고 사용 후 unlock()을 통해 잠금 해제하는 객체 ⇒ 잠금 시 다른 프로세스나 스레드는 접근 불가
    
    **세마포어**
    
    - 일반화 된 뮤텍스
    - 간단한 정수 값 + 두가지 함수(wait(), signal()) 로 공유 자원 접근 처리
    - wait() :자신의 차례까지 기다리는 함수
    - signal() : 다른 프로세스로 순서를 넘겨주는 함수
    - 프로세스나 스레드가 공유 자원에 접근하면 세마포어에서 wait() 작업을 수행 → 프로세스나 스레드가 공유 자원을 해제하면 세마포어에서 signal() 작업 수행
    - 세마포어는 조건 변수 X
    - 세마포어 값은 동시에 변경 불가
        
        **바이너리 세마포어**
        
        - 0과 1의 두 가지 값만 가질 수 있는 세마 포어
        - 구현의 유사성으로 뮤텍스는 바이너리 세마포어라고 볼 수 있음
        - 차이점:  상호 배제가 일어나는 방식이 뮤텍스는 ‘잠금 메커니즘’ , 세마포어는 신호 기반의 ‘ 신호 메커니즘’ 이다
        - 신호 메커니즘 예시 ) 휴대폰에서 노래 듣다 전화가 오면 노래가 중지되고 통화 처리 작업에 관한 인터페이스 등장
        
        **카운팅 세마포어**
        
        - 여러 개의 값을 가질 수 있는 세마포어
        - 여러 자원에 대한 접근 제어에 사용
    
    **모니터**
    
    - 둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 인터페이스 제공
    - 모니터 큐를 통해 공유 작업에 대한 작업을 순차적 처리
    - 세마포어 보다 구현 easy, 상호 배제가 자동

## 교착 상태

두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태

**원인**

- 상호 배제 : 한 프로세스가 자원을 독점하여, 다른 프로세스가 접근 불가
- 점유 대기 : 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상황
- 비선점 : 다른 프로세스의 자원을 강제적으로 가져올 수 없음
- 환형 대기 : 프로세스 A는 B의 자원을 요구, B는 A의 자원을 요구 ⇒ 서로의 자원을 요구하는 상황

**해결 방법**

1. 자원을 할당할 때 애초에 조건이 성립되지 않도록 설계
2. 교착 상태 가능성이 없을 때만 자원 할당 되며, 프로세스 당 요청할 자원들의 최대 치를 통해 자원 할당 여부를 파악하는 ‘ 은행원 알고리즘’ 사용
3. 교착 상태 발생 시 사이클이 있는지 찾아보고 이에 관련된 프로세스를 하나씩 지움
4. 교착 상태는 매우 드물게 일어나기 때문에, 처리 비용이 더 커서 교착 상태 발생 시 사용자가 작업을 종료시킴 ⇒ 현재 사용되는 방식 ex) 응답없음

# 3.4 CPU 스케줄 알고리즘

## 비선점형 방식

프로세스가 스스로 cpu 소유권을 포기하는 방식

강제로 프로세스를 중지시키지 않음 → 컨텍스트 스위칭으로 인한 부하가 적음

### FCFS

- 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘
- 단점 : 긴 프로세스 때문에, ‘준비 큐에서 오래 기다리는 ‘현상 발생 가능

### SJF

- 실행 시간이 짧은 프로세스 우선 실행
- 긴 프로세스가 실행되지않는 starvation 초래 가능
- 평균 대기 시간이 제일 짧음

### 우선순위

- 기존 SJF의 긴 시간의 프로세스가 실행되지 않는 현상을  오래된 작업의 ‘ 우선순위 높이는 방법(aging)’ 을 통해 단점을 보완한 알고리즘

## 선점형 방식

현재 운영체제가 사용

프로세스를 중단시켜 버리고 강제로 다른 프로세스에 cpu 소유권을 할당하는 방식

### 라운드 로빈

- 우선순위 스케줄링의 일종
- 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝 나지 않으면 다시 준비 큐(ready queue)의 뒤로 가는 알고리즘
- 할당 시간이 너무 크면 FCFS가 되고, 짧으면 컨텍스트 스위칭이 잦아 오버헤드가 커짐
- 전체 작업 시간이 길어지지만 평균 응답 시간이 짧아짐
- 로드밸런서에서 트래픽 분산 알고리즘을 쓰임

### SRF

- 중간에 실행 시간이 더 짧은 작업이 들어와도 기존 짧은 작업 전부 수행 후 , 그다음 짧은 작업을 이어나가는 SJF와 달리 SRF는 중간에 더 짧은 게 들어오면 수행하던 프로세스 중단 후 해당 프로세스를 수행하는 알고리즘

### 다단계 큐

- 우선순위에 따른 준비 큐를 여러 개 사용
- 큐마다 라운드 로빈이나 FCFS등 다른 스케줄링 알고리즘을 적용
- 큐 간 프로세스 이동이 안되므로, 스케줄링 부담이 적지만 유연성이 떨어짐
